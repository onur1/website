#!/usr/bin/env bash

set -euxo pipefail

: "${YES:=0}"

if [ "$YES" != "1" ]; then
  exit 1
fi

: "${PUBLIC_S3_BUCKET_NAME:=example.com-public}"
: "${AWS_DEFAULT_REGION:=eu-central-1}"
: "${DOMAIN_NAME:=example.com}"

create_public_bucket() {
  local name="$1"
  local uri="s3://$name"
  local region="$2"

  aws s3 ls "$uri" || \
    aws s3api create-bucket \
      --bucket "$name" \
      --region "$region" \
      --create-bucket-configuration LocationConstraint="$region"
}

set_website_configuration() {
  local name="$1"
  local uri="s3://$name"

  aws s3 website "$uri" --index-document index.html --error-document 404.html
}

upload_bucket_policy() {
  local name="$1"

  if ! aws s3api get-bucket-policy --bucket "$name" --no-cli-pager; then
    echo "c={Version:'2012-10-17', Statement: [ { Sid: 'AddPerm', Effect: 'Allow', Principal: '*', Action: ['s3:GetObject'], Resource: ['arn:aws:s3:::$name/*'] } ]};console.log(JSON.stringify(c))" | node > public_bucket_policy.json
    aws s3api put-bucket-policy --bucket "$name" --policy file://public_bucket_policy.json
  fi
}

copy_changed_files() {
  local search="$1"
  local relative_to="$2"
  local tmpdir="$3"
  local domain_name="$4"

  local relative_path=

  for filename in $search; do
    relative_path="$(realpath "$filename" --relative-to="$relative_to")"

    if [[ -d "$filename" ]]; then
      mkdir -p "$tmpdir/$relative_path"
      copy_changed_files "$filename/*" "$relative_to" "$tmpdir" "$domain_name"
    else
      if ehash=$(curl -I -L "http://$domain_name-public.s3-website.$region.amazonaws.com/$relative_path" 2>/dev/null | grep -Fi etag | awk '{print tolower($0)}' | awk -v FS=": " '/^etag/{print $2}' | tr -d '"' | tr -d '\r\n'); then
        md5sum=$(echo "r=require;c=r('crypto');fs=r('fs');console.log(c.createHash('md5').update(fs.readFileSync(\"$filename\")).digest('hex'));" | node)

        if [ "$ehash" != "$md5sum" ]; then
          cp "$relative_to/$relative_path" "$tmpdir/$relative_path"
        fi
      else
        cp "$relative_to/$relative_path" "$tmpdir/$relative_path"
      fi
    fi
  done
}

upload_changed_files() {
  local homedir=
  homedir="$(realpath "$1")"

  if [[ -z "$homedir" ]]; then
    return 1
  fi

  local region="$2"
  local bucket_name="$3"
  local domain_name="$4"

  local tmpdir="$homedir/tmp"
  local bucket_uri="s3://$bucket_name"

  local path=
  local ehash=
  local md5sum=

  mkdir -p "$tmpdir"

  copy_changed_files "$homedir/public/*" "$homedir/public" "$tmpdir" "$domain_name"

  num_files=$(find "$tmpdir" -mindepth 1 -maxdepth 1 -exec basename {} \; | wc -l | sed 's/ //g')

  if [ "$num_files" -gt 0 ]; then
    (cd "$tmpdir" && aws s3 sync . "$bucket_uri" --no-progress)
  fi
}

create_public_bucket "$PUBLIC_S3_BUCKET_NAME" "$AWS_DEFAULT_REGION"

set_website_configuration "$PUBLIC_S3_BUCKET_NAME"

upload_bucket_policy "$PUBLIC_S3_BUCKET_NAME"

upload_changed_files "$1" "$AWS_DEFAULT_REGION" "$PUBLIC_S3_BUCKET_NAME" "$DOMAIN_NAME"
